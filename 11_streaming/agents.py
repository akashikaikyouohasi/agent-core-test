import logging
import asyncio
from typing import AsyncGenerator
from strands import Agent, tool
from strands.models import BedrockModel
from dotenv import load_dotenv

# AgentCore SDK ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from bedrock_agentcore.runtime import BedrockAgentCoreApp, RequestContext

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
load_dotenv()

# AgentCore ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
app = BedrockAgentCoreApp()

# ãƒ­ã‚°è¨­å®š
logging.getLogger("strands").setLevel(logging.DEBUG)
logging.basicConfig(
    format="%(asctime)s | %(levelname)-8s | %(name)-20s | %(funcName)s:%(lineno)d | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[logging.StreamHandler()]
)


# ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã®å®šç¾©
@tool
def weather_tool(location: str) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸå ´æ‰€ã®å¤©æ°—æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Args:
        location (str): å¤©æ°—ã‚’ç¢ºèªã—ãŸã„å ´æ‰€ï¼ˆä¾‹: æ±äº¬ã€å¤§é˜ªã€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ï¼‰
    
    Returns:
        str: å¤©æ°—æƒ…å ±
    """
    # å®Ÿéš›ã®APIã‚’å‘¼ã¶ä»£ã‚ã‚Šã«ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    weather_data = {
        "æ±äº¬": "æ™´ã‚Œã€æ°—æ¸©22åº¦",
        "å¤§é˜ª": "æ›‡ã‚Šã€æ°—æ¸©20åº¦",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯": "é›¨ã€æ°—æ¸©15åº¦",
        "ãƒ­ãƒ³ãƒ‰ãƒ³": "æ›‡ã‚Šã€æ°—æ¸©12åº¦",
    }
    return weather_data.get(location, f"{location}ã®å¤©æ°—æƒ…å ±: æ™´ã‚Œã®ã¡æ›‡ã‚Šã€æ°—æ¸©18åº¦")


@tool
def calculator(expression: str) -> str:
    """
    æ•°å¼ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    
    Args:
        expression (str): è¨ˆç®—ã™ã‚‹æ•°å¼ï¼ˆä¾‹: "2 + 2", "10 * 5"ï¼‰
    
    Returns:
        str: è¨ˆç®—çµæœ
    """
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€evalã¯å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯é¿ã‘ã‚‹ã¹ã
        result = eval(expression, {"__builtins__": {}}, {})
        return f"{expression} = {result}"
    except Exception as e:
        return f"è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}"


@tool
def text_analyzer(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã¦æ–‡å­—æ•°ã‚„å˜èªæ•°ã‚’è¿”ã—ã¾ã™ã€‚
    
    Args:
        text (str): åˆ†æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        str: åˆ†æçµæœ
    """
    char_count = len(text)
    word_count = len(text.split())
    lines = text.split('\n')
    line_count = len(lines)
    
    return f"""ãƒ†ã‚­ã‚¹ãƒˆåˆ†æçµæœ:
- æ–‡å­—æ•°: {char_count}
- å˜èªæ•°: {word_count}
- è¡Œæ•°: {line_count}
"""


# AgentCoreç”¨ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
@app.entrypoint
async def invoke(payload: dict, context: RequestContext) -> AsyncGenerator[str, None]:
    """AgentCoreç”¨ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰"""
    print("=== AgentCoreçµŒç”±ã§ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã— ===\n")
    
    # BedrockModelã®ä½œæˆ
    bedrock_model = BedrockModel(
        model_id="us.anthropic.claude-3-5-haiku-20241022-v1:0",
        region_name="us-west-2",
        temperature=0.7,
    )
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆï¼ˆãƒ„ãƒ¼ãƒ«ä»˜ãï¼‰
    streaming_agent = Agent(
        model=bedrock_model,
        tools=[weather_tool, calculator, text_analyzer]
    )
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    user_message = payload.get(
        "prompt", 
        "No prompt found in input, please provide a 'prompt' key in the payload"
    )
    
    print(f"è³ªå•: {user_message}\n")
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©
    accumulated_data = []
    event_logs = []
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
    async for event in streaming_agent.stream_async(user_message):
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã®å‡¦ç†
        if event.get("init_event_loop", False):
            msg = "ğŸ”„ ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—åˆæœŸåŒ–\n"
            print(msg, end="")
            event_logs.append(msg)
            yield msg
        elif event.get("start_event_loop", False):
            msg = "â–¶ï¸  ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹\n"
            print(msg, end="")
            event_logs.append(msg)
            yield msg
        elif "message" in event:
            msg = f"ğŸ“¬ æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ: {event['message']['role']}\n"
            print(msg, end="")
            event_logs.append(msg)
            yield msg
        elif event.get("complete", False):
            msg = "âœ… ã‚µã‚¤ã‚¯ãƒ«å®Œäº†\n"
            print(msg, end="")
            event_logs.append(msg)
            yield msg
        elif event.get("force_stop", False):
            msg = f"ğŸ›‘ ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å¼·åˆ¶åœæ­¢: {event.get('force_stop_reason', 'ä¸æ˜ãªç†ç”±')}\n"
            print(msg, end="")
            event_logs.append(msg)
            yield msg
        
        # ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®å‡¦ç†
        if "current_tool_use" in event and event["current_tool_use"].get("name"):
            tool_name = event["current_tool_use"]["name"]
            msg = f"ğŸ”§ ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ä¸­: {tool_name}\n"
            print(msg, end="")
            event_logs.append(msg)
            yield msg
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†
        if "data" in event:
            data = event["data"]
            accumulated_data.append(data)
            print(data, end="", flush=True)
            
            data_snippet = event["data"][:20] + ("..." if len(event["data"]) > 20 else "")
            msg = f"ğŸ“Ÿ Text: {data_snippet}"
            print(msg)
            #yield data
            yield f"{msg}\n"
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
    full_response = "".join(accumulated_data)
    summary = f"\n\n{'='*80}\nâœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†\n{'='*80}\n\nğŸ“Š æœ€çµ‚çµæœ:\n{full_response}\n\n{'='*80}\n"
    print(summary)
    yield summary


if __name__ == "__main__":
    # AgentCore ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
    app.run()
